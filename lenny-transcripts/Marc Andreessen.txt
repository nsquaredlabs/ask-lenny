Marc Andreessen (00:00:00):
If we didn't have AI, we'd be in a panic right now about what's going to happen to the economy. We've actually been in a regime for 50 years of very slow technological change in the face of declining population growth. The timing has worked out miraculously well. We're going to have AI and robots precisely when we actually need them. The remaining human workers are going to be at a premium, not at a discount.

Lenny Rachitsky (00:00:16):
How big of a deal is the moment in time that we are living through right now?

Marc Andreessen (00:00:21):
This is a very, very historic time. AI is the philosopher stone. Now, we have a technology that transfers the most common thing in the world, which is sand, converted into the most rare thing in the world which is thought.

Lenny Rachitsky (00:00:30):
Just spent a lot of time with the most cutting edge AI forward founders.

Marc Andreessen (00:00:34):
The most leading edge founders are thinking of, can you have entire companies where the founder does everything?

Lenny Rachitsky (00:00:38):
There's all this concern that young people, jobs are not going to be there for them, AI is replacing them.

Marc Andreessen (00:00:43):
Everybody wants to talk about job loss, but really, what you want to look at is task loss. The job persists longer than the individual tasks.

Lenny Rachitsky (00:00:49):
What's your sense of just the future of three very specific roles, product manager, engineer, designer?

Marc Andreessen (00:00:54):
There's like a Mexican standoff happening between those three roles. Every coder now believes they can also be a product manager and a designer because they have AI. Every product manager thinks they can be a coder and a designer, and then every designer knows they can be a product manager and a coder. They're actually all kind of correct. What happens is, the additive effect of being good at two things is more than double. The additive effect of being good at three things is more than triple. You become a super relevant specialist in the combination of the domains.

Lenny Rachitsky (00:01:18):
People aren't fully grasping how much this is changing.

Marc Andreessen (00:01:20):
People who really want to improve themselves and develop their career should be spending every spare hour, in my view, at this point, talking to AI, being like, "All right, train me up."

Lenny Rachitsky (00:01:29):
Today, my guest is Marc Andreessen, one of the most seminal figures in tech and in business. He invented the web browser, built the world's largest venture firm. He's also a multi-time founder and an investor in essentially every generational tech company, and is also one of the most clear-minded, lateral, and insightful thinkers about both the past and the future of technology. In this very special conversation, we chat about how unique and significant the moment that we are all living through right now is, what skills he's teaching his kids to thrive in the AI future, what happens to product managers, designers, and engineers in the coming years, where moats exist in AI, what the most AI native founders are doing differently, and so much more that is just scratching the surface of this very deep and important conversation. You are going to walk away from this chat being smarter about what is going on in the world right now and where things are heading.

(00:02:23):
A huge thank you to my newsletter community and folks on X for suggesting topics and questions for this conversation. If you enjoy this podcast, don't forget to subscribe and follow it in your favorite podcasting app or YouTube. It helps tremendously. And if you become an insider subscriber of my newsletter, you get a year free of over 20 incredible products, including a year free of Lovable, Replit, Bolt, Gamma, Innate and Linear, Superhuman, Dev and PostHog, Descript, Wspr Flow, Perplexity, Warp, Granola, Magic Patterns, Raycast, Chappy, RD, MOB and Stripe Atlas. Head on over to lennysnewsletter.com and click Product Pass. With that, I bring you Marc Andreessen after a short word from our sponsors. Today's episode is brought to you by DX, the developer intelligence platform designed by leading researchers. To thrive in the AI era, organizations need to adapt quickly, but many organization leaders struggle to answer pressing questions like, which tools are working? How are they being used? What's actually driving value? DX provides the data and insights that leaders need to navigate this shift. With DX, companies like Dropbox, Booking.com, Adient, and Intercom get a deep understanding of how AI is providing value to their developers and what impact AI is having on engineering productivity. To learn more, visit DX's website at getdx.com/lenny. That's getdx.com/lenny.

(00:03:44):
If you're a founder, the hardest part of starting a company isn't having the idea, it's scaling the business without getting buried in back office work. That's where Brex comes in. Brex is the intelligent finance platform for founders. With Brex, you get high limit corporate cards, easy banking, high yield treasury, plus a team of AI agents that handle manual finance tasks for you. They'll do all the stuff that you don't want to do, like file your expenses, scour transactions for waste, and run reports all according to your rules. With Brex's AI agents, you can move faster while staying in full control. One in three startups in the United States already runs on Brex. You can too at brex.com. Marc Andreessen, thank you so much for being here and welcome to the podcast.

Marc Andreessen (00:04:36):
Awesome, Lenny. Thank you. It's great to be here.

Lenny Rachitsky (00:04:38):
I want to start with just a big picture question. I have a billion directions I want to go, but I think this is going to give us a little bit of a frame of reference. How big of a deal is the moment in time that we are living through right now?

Marc Andreessen (00:04:50):
This is a very, very historic time. I think 2025 was maybe the most interesting year in my entire career and probably life, and I think I would expect 2026 to exceed that.

Lenny Rachitsky (00:05:00):
Wow, that says a lot.

Marc Andreessen (00:05:01):
Yeah, I've seen some stuff. So it feels like two things are happening. One is, the trust that a lot of people have had and kind of what you described as kind of legacy institutions around the world is, I think, in kind of full-scale collapse right now. By the way, there's a lot of data to support that. And so I think there's a lot of structures, orders, and institutions that people have just relied on for a long time that have just proven to not be up for the challenge. And then kind of corresponding with that is, the national and global conversation have become, let's say, liberated. And so this sort of incredible revolution that we have in what I've described as freedom of speech, freedom of thought, ability for people to openly discuss things that maybe they couldn't discuss even a few years ago has just dramatically expanded.

(00:05:46):
And I think that's now on a one way train for just a much broader range of discourse. And then there's also just these incredibly massive geopolitical shifts that are happening. And obviously, the US is changing a lot, Europe is changing a lot, China's changing a lot. Latin America, by the way, is changing a lot. Very dramatic events playing out down there right now. Kind of all over the world, I think a lot of assumptions are being pulled out into the daylight and reexamined. And then it's kind of the fact that all these things are happening at the same time. And so you've got all of these countries and industries where things are kind of increasingly upheaval, but you have AI as this kind of new technology that's going to really affect things. And then you've got people, citizens being able to fully participate and being able to argue things out.

(00:06:27):
And so it's kind of like those three big mega things are all colliding at the same time. And I think we're probably just at the very beginning of all three of those. And those all feel like historical moment shifts, comparable in magnitude to maybe default the Berlin Wall in 1989, maybe the end of World War II, kind of moments like that. It certainly feels like that.

Lenny Rachitsky (00:06:48):
Good God. What a time to be alive.

Marc Andreessen (00:06:52):
Yeah.

Lenny Rachitsky (00:06:52):
In terms of the AI piece, which is where a lot of people are trying to figure out what to do, what do you think isn't being priced in yet in terms of the impact AI is going to have on, say, the world or just people listening?

Marc Andreessen (00:07:04):
I think, at this point, it's pretty clear, with our technology hats on, that this stuff is really working now. There was a ChatGPT moment three years ago. By the way, only three years ago, was the ChatGPT moment. And the big question was, all right, this is incredibly fun and creative. And we have machines now that can compose Shakespearean sonnets and rap lyrics, and this is amazing. But then there was this big question, can you harness this technology for reasoning and for problem solving in domains that really matter, medicine, science, law and so forth? And it turns out the answer to that is yes. And the last 12 months, and especially even just the last three months have really proven that AI can really do... I mean, you're seeing it all now. AI is now developing new math theorems.

(00:07:53):
Over the holiday break, it feels like the AI coding thing really hit critical mass and the world's best programmers, including Linus Torvalds, for the first time over the holiday break basically said, "Yeah, AI is now coding better than we can." And so that's incredibly powerful. And I think we all assume that AI now is going to get really good at reasoning in any domain in which there are verifiable answers. And so that's going to include many very important domains. So the technology feels like it's moving fast and it's going to be working really well. I think the thing that is not well understood, I think a lot of people in the industry have kind of what I would describe as this one dimensional thing, which is, okay, as a result of the technology now working, AI just kind of sweeps the world and changes everything.

(00:08:41):
And I think that's kind of the wrong framer. I think it's based on an incomplete understanding of the world that we live in or the world that we've been living in for the last 80 years. And I would call out two things in particular. So one is, I think it's felt to us, in the US and the West, for the last whatever, 30 years or 50 years, it's felt like we've been in a time of great technological change. But actually, if you look for actually evidence of that, in statistical evidence of that, analytical evidence of that, you basically can't find it. And in particular, economists have a way of measuring the rate of technological change in the economy that is productivity growth, which we could talk about what that means, but basically, it's sort of the mathematical expression of the impact of technology on the economy.

(00:09:24):
And productivity growth for the last 50 years has actually been very low, not very high. So we all feel like it's been very high. There's been lots of technological change. What's actually happening is, it's been very low. And in fact, the pace of productivity growth, like in the US, is running at a half of what it... In my lifetime, in our lifetimes, it's been running at about half the pace that it ran between 1940 and 1970, and it's been running at about a third the pace that it ran between about 1870 to about 1940. And so statistically, in the US, in the West, technology progress in the economy, technology impact in the economy has actually slowed way down. And so the AI thing is going to hit, but it's hitting an environment in which we have actually had almost no technological progress in the actual economy for a very long time. So we could talk about that.

(00:10:11):
And then there's this other just incredible thing that's happening, which is the demographic collapse, it's sort of a Western phenomenon and increasingly global phenomenon, which is the rate of reproduction of the human species is in rapid decline. And there are many countries, including the US, where the rate of reproduction is under two, meaning that many, many countries around the world, by the way, including China, which is a really big deal, are actually going to depopulate over the next century. And so you have this kind of precondition that says there's actually been very little technological progress happening in the world and the world is going to depopulate. And so AI is going to enter a world in which those two things are true. And I think this is incredibly important because we actually need AI to work in order to get productivity growth up, which is what we need to get economic growth up.

(00:10:59):
And we actually need AI to work because we're going to need machines to do all the jobs that we're not going to have people to do because we're literally going to depopulate the planet over the next 100 years. And so I think the interplay of these factors is going to be much more interesting, and frankly, more complex than a lot of people have been thinking.

Lenny Rachitsky (00:11:15):
I'm going to follow this thread about kids. I know you have a kid, and my favorite lenses into how people think and what they value is what they're teaching their kids, what they're steering their kids towards. Are there specific skills or even careers that you're steering your kid towards?

Marc Andreessen (00:11:32):
The way I think about this, we have a 10-year-old, we actually homeschool and so we think a lot about this. So I think the way to think about the impact of AI on, specifically, people as individuals, it's actually, a lot of people just focus on this kind of very, I would say, straightforward or overly simplistic view of just literally job losses, which we can talk about. But there's two specific things at the level of an individual person or an individual kid. So I think it's pretty clear that AI is going to take people who are good at doing things and it's going to make them very good at doing things. And so it's going to be a tool that's going to raise the average across the board. And look, you see that playing out already. Anybody who's in a position where they need to write something, design something, write code or whatever, if they're pretty good at it today, they use AI and all of a sudden they're very good at it.

(00:12:21):
And so there's sort of that aspect to it. And I think the way the education system at large is going to teach AI is going to be based hopefully a lot on that. But then there's this other thing that's happening, which we're also starting to see, and we're really seeing it particularly in coding right now, where the really great people are becoming spectacularly great. And so you kind of use the term, you think about the super empowered individual. So the individual who is really good at coding, really good at making movies, really good at making songs, really good at making art, or whatever those things are, or podcasting or hopefully venture capital. If you're very good at it and you can really harness AI, you can become spectacularly great and super productive. I'm sure you have a lot of friends in this category as well, but the really, really good coders are experiencing this right now.

(00:13:19):
My friends who are really good coders are like, "Oh my God, all of a sudden, I'm not twice as good as I used to be, I'm 10 times as good as I used to be." And so I think, at the unit of N=1 of an individual kid, I think the question is, how do you get them into position where they're kind of this super empowered individual such that they're going to be really kind of deep in whatever it is they're going to do, but they're going to be deep in a way that's going to let them fully use the power of AI to be not just great, but to be spectacularly great? I think that's the real opportunity, and at least that's what we're shooting for and that's what I would encourage parents to shoot for.

Lenny Rachitsky (00:13:53):
So when I heard there is essentially agency, this word that we see on Twitter all the time is building agency, them not waiting for someone to tell them what to do, figuring out what to do.

Marc Andreessen (00:14:01):
Yeah. Yeah. So this term agency that's become very, very, very popular, certainly in California for the last couple of years, it's really interesting because I had a lot of trouble with this early on, because I'm like, "Agency? Okay, what are they talking about?" And what they're kind of talking about is initiative, you could just do things. What is it? The [inaudible 00:14:25] has the great term, live player, you can be a primary participant in events. And at first, I was like, "Well, yeah, that's kind of obvious, of course." And then I'm like, "Oh, actually, it's not so obvious anymore." Because to your point, I think so much of our society is based on, there are all these rules and everybody gets taught kind of by default, you're supposed to follow all these rules. And then if you break the rules, everybody gets freaked out.

(00:14:51):
It's like, "Oh my God, he broke the rules." And so we have somehow worked our way kind of psychologically, sociologically into a state in which I guess the natural assumption for a lot of people is the thing that you... For example, the thing you want to train kids to do is follow all the rules. And you could argue that, for example, K through 12 school system or whatever has gotten more and more focused on that over time. And again, especially unit N=1 of your kid, it's like... And look, there's something to be had. I just had this conversation with my 10-year-old last night, actually, I rolled out the concept of, in order to lead, you must first learn to obey. In order to issue orders, you must learn how to follow orders and trying to keep him with some level of structure in his life, and not just pure agency.

(00:15:40):
But yeah, and so look, some rules are important and so forth. But yeah, no, look, there's just a huge premium in life on being somebody who is able to fully take responsibility for things, fully take charge, run an organization, lead a project, create something new. And maybe that has been maybe a little bit diminished in our culture over the last 30 years. It's healthy that there's now a term for that that is coming back into vogue. And again, that's how I view AI for kids is like, okay, AI should be the ultimate lever on the world for a kid with agency to be able to say, "Okay, I can actually be a primary contributor, whether that's I can be a primary contributor in everything from developing new areas of physics to writing code, to being an artist, to writing novels, whatever that thing is, I can fully participate in the world. I can really change things." And the combination of that idea combined with this technology feels very healthy to me.

Lenny Rachitsky (00:16:35):
What is that quote about, "Give me a lever and I'll move the world"?

Marc Andreessen (00:16:38):
And I'll move the world. Yeah, that's exactly right. Well, so it's actually funny you mentioned that. So the early scientists, including Isaac Newton, were super obsessed with this concept of alchemy. Like Newton, he developed Newtonian physics and he developed calculus and all these things. But the thing he was really obsessed with was alchemy, which was the thing he could never get to work. And alchemy was the transmutation of lead into gold, which meant the transmutation of something that was very common, which was lead into something that was very rare and valuable, which was gold. He spent decades trying to figure out this thing called the philosopher stone, which would be basically the machine or the process that would be able to transmute the common thing into the rare thing, lead into gold, and he never figured it out. It was incredibly frustrating. Nobody ever figured that out. And now, we literally with AI have a technology that transfers sand into thought. Right?

Lenny Rachitsky (00:17:31):
That just blew my mind.

Marc Andreessen (00:17:33):
The most common thing in the world, which is sand, converted into the most rare thing in the world, which is thought. And so AI, it is the philosopher stone. It is that. It actually is that. And it's just this incredibly powerful tool. And that's where I get so excited. And again, this is what we're doing with our 10-year-old, which is like, all right, primary thing that we want to make sure to do is, to make sure that he knows fully how to leverage and get benefit out of the philosopher stone, which is to say AI. And then that's certainly central to everything we're teaching him.

(00:18:04):
There's this meme going around that Silicon Valley people don't let their kids use computers. And there may be a handful of people who are like that. I don't know. I think it's more, honestly, the other way around, which is, the more you're plugged into stuff in Silicon Valley, the more important it is to make sure that your kids actually fully understand this and know how to use it. And that's certainly the mode that we're in. And that's certainly the mode that I would encourage parents to think about.

Lenny Rachitsky (00:18:26):
I did not know your kid was homeschooled. That is super interesting. It's almost a statement on education in today's day. Maybe, is there any thoughts there? And just for folks that maybe aren't in your tax bracket that want to help their kids be successful, maybe homeschooled, maybe not, what advice would you have?

Marc Andreessen (00:18:42):
This is the challenge. And again, this kind of goes to your original question, which is education, there's two completely different ways to think about education. The way that it's usually thought about and talked about is kind of at the level of a nation. So it's like a national level issue or maybe a state level issue in the US, which is basically, how do you educate all the kids? And of course, that's incredibly important. And of course, you're going to need some level of large scale system, like the national K through 12 school system or something like that in order to do that. But then there's this other question, which is like, N=1, for an individual kid, what can you do with an individual kid? And so I'll just give you the ultimate answer to that question, which is, it's been known for centuries that the ideal way to teach a kid at the unit of N=1, by far the ideal way to do it is with one-on-one tutoring.

(00:19:36):
If you just have an individual kid and the goal is to maximize an individual kid, by far you get the best results with one-on-one tutoring. And this is something that every royal family knew in history. It's something that every aristocratic class knew in history. There's all these amazing examples. Alexander the Great was tutored by Aristotle. He took over the world. Many of the great kings, queens, royal families, aristocrats and so forth over the course of centuries kind of always had this approach. There's actually also statistical evidence, analytical evidence that this is correct. There's this massive question in the field of education, which is, how do you improve educational outcomes? And basically, it turns out it's very hard to improve educational outcomes except there's one method that always does it, which is called the Bloom's 2 Sigma effect, which is there's one method of education that routinely raises student outcomes by two standards of deviation and will take a kid from the 50th percentile to the 99th percentile and that's one-on-one tutoring. So again, if you go back to N=1, you have a kid and a tutor and they're in this very tight loop with each other, where the kid is able to constantly kind of be on the leading edge of what they're capable of doing and they can move incredibly fast and they get kind of correction in real time, you get these better outcomes. But to your question, it's never been economically feasible for anybody other than the richest people in society to be able to provide one-on-one tutoring for kids. AI provides the very real prospect of being able to do that, because obviously now, if you have a kid that's super interested in something and they can talk to an LLM about it and they can ask an infinite number of questions and they can get instantaneous feedback. And in fact, you can even tell an LLM, it's like, "Teach me how to do the following." And you can say, "Wow, I don't quite understand what you're saying. Numb it down for me a little bit."

(00:21:15):
"Okay, now quiz me, do I actually understand this?" People can just do this today. And so I think there's this massive opportunity for parents in many walks of life, with a little bit of time at focus, to be able to say, " Okay, my kid's probably still going to go through a traditional education system, but I'm going to augment this with AI tutoring." And of course, there's going to be tons of startups, and there already are, that are going to try to build on all the products and services for this. Khan Academy, on the nonprofit side, has a big push to do this. And so I think the broad answer might be a hybrid approach with schools plus one-to-one tutoring through AI. You may have heard, there's this great new private school system called Alpha, in which everything I just described is kind of the basis of their philosophy, which is, it's a combination of in person schools and teachers, but it's also heavily based on AI and AI tutoring.

(00:22:04):
And so I think there is a magic formula in here that I think is going to apply much more broadly. And really, for parents interested in this, now it'd be a great time to really start to think hard about that and to look at the options.

Lenny Rachitsky (00:22:17):
It's interesting because there's all this concern that young people, jobs are not going to be there for them, AI is replacing them. On the flip side, there's what you're describing here. It feels like people coming in learning today are going to move so fast and learn so much more. And where do you sit on this divide of, young people are in big trouble or they're actually going to be the ones winning in the end?

Marc Andreessen (00:22:38):
Yeah. So the job substitution, job loss thing is just, it's very reductive. I think it's an overly simplistic model. And again, it goes back to what I said at the very beginning, which is, we've actually been in a regime for 50 years of very slow technological change in the economy. And so again, like I said, it's at half the rate of the previous era and then a third of the rate of 100 years ago. And so we're coming out of this kind of phase where we've had almost no technological progress in the economy, we've had remarkably little job churn as a result of that relative to any historical period. And so even if AI ticks up, even if AI triples productivity growth in the economy, which would be a massively big deal, it would take us back to the same level of job churn that was happening between 1870 and 1930.

(00:23:17):
And if you go back and you read accounts of 1870 to 1930, people just thought the world was a watch with opportunity. At that rate of technological transformation, kids were able to develop new careers into new areas of the economy, building new kinds of products and services. I mean, a huge part of everything in our modern world today was kind of invented and proliferated during that period. And so even if AI triples the pace of economic change in the economy, it's going to just translate to a much higher rate of economic growth, it's going to translate to a much higher rate of job growth. And there'll be some level of task level and job level substitution that will take place, but that will be swamped by the macro effects of economic growth and innovation that will happen. And then corresponding to that, there'll be hiring booms, quite honestly, I think all over the place.

(00:24:02):
And then again, go back to the other thing, which is like, this is all happening in the face of declining population growth and increasingly population shrinkage. And so human workers in many, many, many countries over the next 10, 20, 30 years are going to be at more and more of a premium, literally because you're going to have shrinking population levels. We don't really want to get into politics particularly, but it does feel like the world broadly is going to reverse course on the rates of immigration that we've had for the last 50 years. It seems to be kind of a broad-based thing happening with rise to nationalism, concerns about the rate of immigration and immigration historically in countries like the US, it's kind of ebbed and flowed over time based on how the national mood shifts. And so if you sort of combine in a country like the US or any country in Europe, if you combine declining population with less immigration, the remaining human workers are going to be at a premium, not at a discount.

(00:24:57):
And so I think that combination of faster productivity growth, faster economic growth, and then slower population growth and less immigration actually means there's going to be much less of this kind of dystopian no jobs' thing. I just think it's probably totally off pace.

Lenny Rachitsky (00:25:10):
That is extremely interesting. So what I'm hearing is, you're not super worried about job loss. Is the key here that the timing kind of just works out, this population decrease, all these kind of have to line up for there not to be this massive job loss with AI?

Marc Andreessen (00:25:24):
Yeah. Well, look, if we didn't have AI, we'd be in a panic right now about what's going to happen to the economy. Because what we'd be staring at is a future of depopulation. And depopulation without new technology would just mean that the economy shrinks. So it would mean that the economy kind of itself kind of shrinks over time. The opportunity diminishes. There are no new jobs, there are no new fields, there's no new source of consumer demand for spending on things. And so you would be very worried about going into a period of severe decline of stagnation. And essentially, you'd be looking at these very dystopian scenarios of an economy kind of self-euthanizing itself over time. And so you'd be very worried about the opposite of what everybody thinks that they're worried about. The only reason we're not worried about that is because we now know that we have the technology that can substitute for the lack of population growth and then also for the lack of immigration that's likely.

(00:26:16):
And so I would say the timing has worked out miraculously well in the sense of, we're going to have AI and robots precisely when we actually need them, to keep the economy from actually shrinking. And I just think that's just a fundamentally good news story.

(00:26:31):
To get to the mass job loss thing that people are worried about on the other side of things, you'd have to look at far, far, far higher rates of productivity growth. You'd have to look at rates of productivity growth that are 10, 20, 30, 50% a year, something like that, which are orders of magnitude higher than we've ever had in an economy in the history of the planet. It's possible that we get that. I mean, look, I have my utopian temptation along with everybody else. If AI radically transforms everything overnight, then maybe let's play out the kind of utopian-

Marc Andreessen (00:27:00):
... radically transforms everything overnight. Then maybe let's play out the kind of utopian scenario. You get to a much higher level of productivity growth, you get to much higher level of technological change. Corresponding to that, you'll have a massive economic boom. You'll have a massive growth in the economy. And then corresponding with that, you'll have a collapse in prices. And so the price of goods and services that are, whatever you're going to call it, affected by or commoditized by AI, the prices of those goods and services will collapse. There'll be price deflation. And then as a consequence of price deflation, everything that people are buying today gets a lot cheaper. And that's the equivalent of a gigantic increase in wealth across the society, right?

(00:27:39):
Take it this way. This is actually worth talking about because people, I think, get sideways on this issue. So if AI is going to transform the economy as much as the, whatever, utopians or dystopians or whatever kind of thing that it will, the necessary economic calculation of what happens is massive productivity growth. The consequence of massive productivity growth, what that literally means mechanically is more output requiring less input. So, you get more economic output for less input. So you're substituting in AI for human workers or whatever. And as a consequence, you get this massive boom in output with much lower input costs. The result of that is you get gluts of goods and services in all those affected sectors. The result of those gluts is you get collapsing prices. The collapsing prices mean that the thing today that costs you $100, now costs you $10, and now costs you $1. That's the equivalent of giving everybody a giant raise because now they have all this additional spending power. That additional spending power then translates to economic growth, the development of new fields. Everybody's materially much better off very quickly.

(00:28:41):
And then by the way, to the extent that you do have unemployment coming out the other side of that, it's now much cheaper to provide the social safety net to prevent people from being immiserated because the prices of all the goods and services that a welfare program has to pay from, they're all collapsing. And so, the price of healthcare collapses, the price of housing collapses, the price of education collapses, the price of everything else collapses because of this incredible impact that AI is having.

(00:29:04):
And so in this kind of utopian/dystopian scenario that people have, there's no scenario in which everybody's just poor. In fact, it's quite the opposite, which is everybody gets a lot richer because prices collapse. And then it's actually much easier to pay for the social safety net for the people who, for some reason, can't find a job. And so maybe we end up in that scenario. I mean, the optimistic part of me says, "Yeah, maybe AI is that powerful, and maybe the rest of the economy can actually change to accommodate that, and maybe that'll happen." But the result of that is going to be a much better news story than people think it's going to be. And again, everything I've just described, by the way, is just a very straightforward extrapolation of very basic economics. I'm not making any bold predictions of what I just said. This is just a straightforward mechanical process that plays itself out if you have higher rates of productivity growth, which are necessarily the results of higher rates of technological growth.

(00:29:51):
And so, I think we're looking at... And to be clear, I think we're looking at a world that's not radically transformed the way that, maybe, the utopians think that it will be or the dystopians think it will be. I think it'll be more incremental for reasons we can discuss, but I think that incremental, overwhelmingly, I think that process is going to be a good news process. And then even if it's much faster, it's also going to be a good news process. It'll just be a good news process in the other way that I just described.

Lenny Rachitsky (00:30:15):
I love hearing optimism and good news. I will also add that you've been... I was researching you ahead of this chat, and you've been right so many times about where the world is heading. That's why I'm especially excited to talk to you. I'll give you a short list. I imagine there are many more things. So one, you were right about the Web and web browsers becoming important. You were right about software eating the world. Check. In 2011, you said that in 10 years, we're going to have 5 billion people using smartphones. And I believe the actual number ended up being six billion. Also, you had this debate with Peter Thiel that I came across, where you were debating whether technologies stop progressing or if new technology will continue to emerge. And you were arguing there's progress. Progress will continue. And he was like, "No, I think we're done with cool technology." You were right.

(00:31:05):
I imagine there are many more things you were right about. So again, I love hearing your predictions because I feel like they're actually going to turn out to be correct.

Marc Andreessen (00:31:16):
I was going to start by saying, I've been wrong about tons of things, but I buried those out back behind the shed.

Lenny Rachitsky (00:31:21):
Delete them from the internet. No browser can discount them.

Marc Andreessen (00:31:24):
Yes. Yes, I have them nuked out of the internet archives so that they're never seen again. So, I'm wrong plenty of times also. But yeah, look, I think some of those, I got right. By the way, I will say on the Peter one, I've come much more around to Peter's point of view. I would probably argue that one quite a bit differently today than I did, and I would give his view, I think, a lot more credit. And it actually goes to the discussion that we did, the conversation we just had, which is the... The real form of what Peter was arguing was we have lots of process in bit, we have lots of progress in bits, but we have very little progress in atoms. And that's the real core of what he was arguing. And I think I was a little bit, I don't know, missing that or glossing that over a little bit because I was so focused on making sure people understood, "No, there actually is still progress happening in bits."

(00:32:11):
But I think a lot of his critiques around the lack of progress in atoms is real. And again, this goes back to this thing of like... And he's talked about this for a long time. In the last 50 years, there has just been very little technological innovation in most of the economy. There's been very little technological innovation, in particular, anything involving atoms. There's been very little real-world technological change. There just hasn't been. The built world is just not that different today than it was 50 years ago. And again, if you contrast that, if you compare and contrast 1870 to 1930, it was a dramatically different world. If you contrast 1930 to 1970, it was a dramatically different world. If you contrast 1970 today, it's not that different.

(00:32:48):
And look, you just see that you could just walk around and it's just like, "Oh yeah, there's a bunch of buildings that were built in 1960, and there's a bridge that was built in 1930, and there's a dam that was built in like 1910, and there's a city that was founded in 1880." And like, "What have we done? Where are our new cities? Where are new dams? Where's the California High-Speed Rail? What's going on here?" And so, I think he is right about a lot of that. Again, this is also why I think that AI is not going to have as rapid... It's not going to be, again, this kind of utopian or dystopian view of everything changes overnight. I think it just can't happen because of the reasons that Peter articulates, which is there's so much about how the world works that's basically just like wrapped up in red tape: like bureaucratic process, rules, restrictions, the politics. By the way, unions, cartels, oligopolies, there's all these structures in the world that are economic or political or regulatory structures that basically prevent things from changing.

(00:33:55):
And so let's take a great example: AI's impact on the healthcare system. By rights, AI is going to have a dramatic impact on the healthcare system, and in very positive ways. But large parts of the medical system today, they are cartels. And so the doctors are a cartel, and nurses are a cartel, hospitals are a cartel. Then there's this push to nationalize all the healthcare systems, and then you've got a government monopoly. And guess what cartels of monopolies don't like, is they don't like rapid change. And so you show up as a kid and you're like, "Wow, I've got this new technology to do AI medicine." And they're like, "Oh, does it threaten doctor jobs? In that case, we're going to block it." And I think a lot of consumers, by the way... I see this in my life, and you'll probably see this in your life also, which is ChatGPT is almost certainly a better doctor than your doctor today, but ChatGPT can't get a license to practice medicine. So, it can't substitute for a doctor. It can't prescribe medications. It can't perform procedures. And so, there are these...

(00:34:56):
Anyway. So Peter, I think, was very articulate, and has been for a long time on like, "No, there are actually real structural impediments in the economy and in the political system that we have, that actually prevent..." The rates of change, that are anywhere near the rates of change that people have in the past. And you can maybe say, optimistically, maybe the presence of the new magic technology of AI, maybe it causes us to revisit a lot of these assumptions for the first time in decades, to really say, "Okay, is this really the world we want to live in? Don't we actually want to get to the future faster?" So maybe, that would be the optimistic view.

Lenny Rachitsky (00:35:26):
"It's time to build," somebody famously said. In my calendar, I actually have that as my... When I start to work, "It's time to build."

Marc Andreessen (00:35:26):
Yes.

Lenny Rachitsky (00:35:33):
That's my block in the morning of the day. Thank you for that.

(00:35:36):
Okay. I love the way you go from just macro to just like N-of-1, and I want to go to N-of-1. A lot of the listeners of this podcast are product managers, they're engineers, they're designers. There's a lot of founders, but there's also a lot of non-founders. There's a lot of people building product that aren't founders. And obviously, a lot of people are worried about where their career is going. "Is one of these roles going to disappear?" "Is one of these roles are going to do really well?" " How do I stay up to date?"

(00:36:01):
You're close with a lot of teams, a lot of product teams. What's your sense of just the future of these three very specific roles: product manager, engineer, designer?

Marc Andreessen (00:36:10):
This, I think, is a really funny question. These three roles in particular, obviously, are the central roles for building for tech companies. So, the way I've been describing it is... You know the concept of the Mexican standoff, right? Which is the movie scene where the two guys have guns point at each other's heads?

Lenny Rachitsky (00:36:23):
Mm-hmm.

Marc Andreessen (00:36:24):
And then there's... If you watch John Woo movies, he loves to have... He does the three-way Mexican standoff, where you've got like a triangle, people. And of course, John Woo movies, they've got guns in both hands. So, each is aiming at the other two and you've got this kind of standoff situation. And so the way I've been describing this is there's like a Mexican standoff happening between those three roles: between product manager, designer, and coder. Specifically, the following, which is every coder now believes they can also be a product manager and a designer because they have AI, every product manager thinks they can be a coder and a designer, and then every designer knows they can be a product manager and a coder. And so, people in each of those roles now know or believe that with AI, they don't need the other two roles anymore. They can do that because they can have AI do that. And then of course, there's the real irony, which is all three of them are going to realize that AI can also be a better manager. So, they're going to be aiming the guns up the org chart, but that's the next phase. And what I think is so fascinating about this Mexican standoff is they're actually all kind of correct, I think. Which is, AI is actually a pretty good... It's actually now a really good coder, it's actually now a really good designer, and it's also a really good product manager. It's actually good at doing all three of those things, or at least doing a lot of the tasks involved in those three jobs.

(00:37:41):
And so again, this goes back to this idea of the super-empowered individual. Where if I'm a coder, step one is I need to make sure that I really understand AI coding, and what that means, and how coding is going to change in the future. I need to understand specifically how to go from being a coder who writes code entirely by hand to being a coder who orchestrates a dozen instances of coding bots. There's a change in the actual job of coding itself, which is happening right now. But the other part of it is, "Okay, how do I become that super-empowered individual? How do I become a coder that also then harnesses AI so that I can also be a great product manager, and I can also be a great designer?" And then the same thing for the product manager, which is, "How do I make sure that I can now use coding tools? How do I make sure I can also do AI-based design?" And the same thing for the designer, which is, "How do I use AI to also become a coder, and also become a product manager?"

(00:38:32):
And then what you get is maybe, those individual roles change. Maybe, those are not any more sort of stovepipe roles the way that they have been for the last 30 years or whatever. But what happens is that the talented people in any of those roles become super powered, and they become good at doing all three of those things. And then, those people become incredibly valuable, because then those are people who can actually build and design new products from scratch, which is the most valuable thing. And so, I think that's the opportunity.

Lenny Rachitsky (00:39:02):
I love this answer. So what I'm hearing is, essentially, if you're amazing at any of these three roles, you will do well.

Marc Andreessen (00:39:08):
Number one, if you're amazing at these roles, that's great. But also, part of being amazing in these roles is also being able to fully harness the new technology. So if you're a master coder today and you don't ever get to the point where you figure out how to use AI to leverage your coding skills and do more, at some point you are going to hit an issue.

(00:39:28):
Here's another way economists talk about this, which is there's the concept of the job, but the job is not actually the atomic unit of what happens in the workplace. The atomic unit of what happens in the workplace is the task. And then the way the economists think about it is a job is a bundle of tasks. Everybody wants to talk about job loss, but really, what you want to look at is task loss, the tasks changing.

(00:39:52):
The classic example of task changing. Classic example of task changing was once upon a time, executives never used typewriters or personal computers themselves. If you were a vice president of a company in 1970 or whatever, you did not have a typewriter or a computer on your desk typing things. You had a secretary who you dictated memos to. And then there was this change where emails started to show up. And what would happen was the job of the secretary, it went from... The job of the secretary changed from sending out letters with stamps on them to sending or receiving emails with the other admins. Then the secretary would print out the email and bring it into the executive's office. And the executive office would read the email and paper, scroll the reply and give that message back to the secretary, who would go back and type it into the computer on his or her desk, and send it as an email.

(00:40:38):
Fast-forward to today, none of that happens. Now, executives just do all their own email. They still have secretaries or admins, but they're now doing different tasks. They're travel planning and orchestrating events, and doing all of these other things that the great admins do. And then the task set, ironically, of the executive, has expanded to do actually more of the clerical work themselves actually. Like, sit there and type their own memos. Which again, 50 years ago, they never would've done that. And so the executive job still exists, the secretary job still exists, but the tasks have changed. And I think that's a great example of what's going to happen. In coding, the tasks are going to change. Product management, the tasks are going to change. Designer, tasks are going to change. And so, the job persists longer than the individual tasks. And then as the tasks change enough, then that's when the jobs change.

(00:41:28):
And so at the level of individual, you want to think of like, "Okay. I have this job, the job is a bundle of tasks. I need to be really good at making sure that I can swap the tasks out. I can really adapt, use the new technology." Get really good at AI coding, for example. And then you want to add skills. "I can also get really good at design. I can also get really good at product management because I've got this new tool." So, you want to pick up more and more scope as you do that. And then 10 years from now, is your job title coder or coder/designer/product manager? Or is it just, "I build products"? Or is it just, "I tell the AI how to build products"? It's like whatever that job is called, who even knows what it's going to be, but it's going to be incredibly important because the people doing that job are going to be orchestrating the AI.

(00:42:10):
And so that's the track that the best people are going to be on, and I think that's the thing to lean hard into.

Lenny Rachitsky (00:42:17):
I think people aren't fully grasping just, specifically, software engineering and how much that is changing. It's pretty clear we're going to be in a world soon where engineers are not actually writing code, which I think, a year ago, we would not have thought. And now it's just, clearly, this is where it's heading. It's like there's going to be this artisanal experience of sitting there writing code, which is so crazy how much that job is going to change.

Marc Andreessen (00:42:39):
Yeah. So again, here, I go back. And again, pardon maybe the history lesson, but I go back coding. So, the first...

(00:42:47):
Do you know the original definition of the term calculator? Do you know what that referred to?

Lenny Rachitsky (00:42:50):
No.

Marc Andreessen (00:42:50):
It referred to people. So back before there were like electronic calculators or computers or any of these things, the way that you would actually do computing, the way that you would do calculating... Like the way that an insurance company would calculate actuarial tables or the military would like calculate, I don't know, whatever troop logistics formulas or whatever it was. The way that you would do it is you would actually have a room full of people. And by the way, these are like big rooms. You could have hundreds or thousands or tens of thousands of people doing this. And you would actually figure out... Somebody at the head of the room was responsible for whatever the mathematical equation was. And then, they would parcel out the individual mathematical calculations to people sitting at desks, who were doing them all by hand. And that job title was those people were calculators.

(00:43:35):
And so, we've gone from a world in which you literally have people doing mathematical equations by hands. Then, we got the first computers. The first computers, of course, didn't have programming languages. They only had machine code. So, the first computers were programmed with 1s and 0s. And so the task of the programmer became, "Do the 1s and 0s," and then that became punch cards. And you can still... There's still people, kicking today, whose job as a programmer was to build the punch cards. And then you got, actually, this big breakthrough, which was called assembly language, which was basically the way to do machine code but with some level of English added to it. And then the best programmers did assembly language. And then when I was coming up, it was higher level languages like C, that compiled into machine code, and that's what programmers did. And then I still remember when scripting languages... We developed JavaScript at Netscape, and then Python took off, and Pearl, and these other scripting languages.

(00:44:27):
When scripting language took off in the 2000s, there was this big fight in the technical community, which is, "Scripting, real programming or not?" because it's like it's kind of cheating. Because real programmers write code that compiles to machine code, and real programmers do memory management themselves, and they do all of this whole craft of writing a C code. And these JavaScript or Python programmers are just doing this kind of lightweight things. Does it even really count as coding? And of course, the answer is yes, it very much counted. And now, most coding is done with the scripting languages, which have...

(00:44:58):
You see my point. The scripting languages have abstracted away, like, five layers of detail underneath that, that people used to do by hand, and they don't anymore. And then to your point, AI coding is the next layer on that. AI coding actually abstracts the way the process of actually writing the scripting code. And so in one sense, this is a really big deal for all the obvious reasons. But on the other hand, it's like, "Okay, this is the next layer of the task redefinition under the job of programmer." Now, what's the job of the programmer? To your point, it's not necessarily to write the code by hand. But what it is now is, all right, if you talk to the world's best programmer of yesterday, what they'll tell you is, "Oh, my job is I'm sitting there and I'm orchestrating 10 code bots, coding bots that are running in parallel."

(00:45:39):
And literally, they sit there and they shift from browser to browser, or terminal to terminal. Their day job now is arguing with the AI bots to try to get them to write the right code, and then debug it and fix the problems, and change this back, and do all of these things. And so now, the job of the programmer is to argue with the coding bots. But if you don't know how to write the code yourself, you don't know how to evaluate what the coding bots are giving you. And so, you asked about the 10... Our 10-year old is super into computers and super into programming. He's using Claude, and ChatGPT, Copilot, and all of these things. And what I'm telling him is like, "Look..." And by the way, he loves vibe coding. He's on Replit all of the time doing vibe coding, doing games. He's sitting there. It's hysterical because he's sitting there. It's a 10-year old basically, who spends two hours at dinner arguing with an AI for fun.

(00:46:27):
But what I'm telling him is, "No, look, you need to still fully understand and learn how to write and understand code, because the coding bots are giving you code. If it doesn't work, or if it's not doing what you expect, or it's not fast enough or whatever, you need to be able to understand the results of what the AI is giving you." In the same way that somebody who's writing scripting language code does need to understand ultimately how the microprocessor works. And so again, it's kind of this up leveling of capability where you actually want the depth to be able to go down and be able to understand what the thing is actually doing, even if you're not spending your day actually doing that by hand. And again, I look at that and I'm like, "Okay. Now, programmers are going to be 10 times or 100 times or a thousand times more productive than they used to be."

(00:47:04):
And that is, overwhelmingly, a good thing. The tasks are definitely changing. The nature of the job is changing. But are human beings going to be involved in the coding process and overseeing the AI coding and all of that? And the answer is, of course, absolutely 100%. No question.

Lenny Rachitsky (00:47:22):
So you're in the camp of still learning to code is still a valuable skill?

Marc Andreessen (00:47:24):
Oh yeah, totally. Again, if you want to be one of these super... Look, if you just want to put yourself on autopilot, and like, "I can't be bothered. I'm just going to have AI write the code, and it's going to generate whatever it does and that's fine. And I'm going to be..." If the goal is to be a mediocre coder, then just let the AI do it. It's fine. The AI is going to be perfectly good in generating infinite amounts of mediocre code. No problem. It's all good. If the goal is, "I want to be one of the best software people in the world, and I want to build new software products and technologies that really matter," then yeah, you, 100%, want to still... You want to go all the way down. You want your skillset to go all the way down to the assembly, to assembly and machine code. You want to understand every layer of the stack. You want to deeply understand what's happening at the level of the chip, and the network, and so forth.

(00:48:06):
By the way, you also really deeply want to understand how the AI itself works, because you want to... If people understand how the AI works, they're clearly able to get more value out of it than somebody who doesn't understand how it works. You're always more productive if you know how the machine works when you use the machine. And so the super-empowered individual on the other end of this that wants to do great things with the new technology, yes, you 100% want to understand this thing all the way down the stack because you want to be able to understand what it's giving you. And when something doesn't work or when something isn't right, you want to be able to really quickly understand why that is.

(00:48:38):
By the way, again, this goes back to education. AI is your best friend at helping you learn all of that because it's like, "Oh, I need to understand. I don't know, this isn't fast enough." I need to figure out... As a coder, I need to figure out how to do a different approach to memory management or something. And you can be like, "Well, shit. I don't quite know how to do that. Okay, AI, let's spend 10 minutes. Teach me how to do this. Teach me what this all means." So all of a sudden, you have this incredibly synergistic relationship with the AI, where it's also helping you get better at the same time that's doing a lot of work for you.

Lenny Rachitsky (00:49:08):
By the way, I was going to say, I was a big Pearl programmer. I was an engineer for 10 years, and that was my language of choice.

Marc Andreessen (00:49:14):
Do you remember? I don't know when you were doing it, but do you remember... At least early on, did you ever hit this where C coders were looking down their nose at you and being like-

Lenny Rachitsky (00:49:23):
For sure. It was like, "This is so slow. It's not going to scale. What are you spending all your time on this thing?"

Marc Andreessen (00:49:27):
Yeah, exactly. And of course, and again, it started this thing where they were sort of correct. Which is, at the beginning, it wasn't fast enough or whatever. By the end, they were definitely wrong, which is it got much better, much faster. And it swept the world. Most coding today happens as scripting languages.

(00:49:42):
And then by the way, along the way, the people who really understood the scripting languages and the people who understood all the lower level systems, they were the ones who were able to actually make the scripting languages actually work really well. And so, that was a great example of this kind of adaptation. And again, the result of that was a far higher number of people writing code with scripting languages than were ever writing code with lower level languages. And I think this will just be a more dramatic version of that.

Lenny Rachitsky (00:50:04):
I love that Pearl was designed by a linguist. I don't know if you remember that part. And that's what made it so nice to code with.

Marc Andreessen (00:50:10):
That's funny because, of course, it was so notorious for being impossible to understand.

Lenny Rachitsky (00:50:15):
How ironic.

Marc Andreessen (00:50:17):
Yes.

Lenny Rachitsky (00:50:18):
This episode is brought to you by Datadog, now home to Eppo, the leading experimentation and feature flagging platform. Product managers at the world's best companies use Datadog, the same platform their engineers rely on every day to connect product insights to product issues like bugs, UX friction, and business impact. It starts with product analytics where PMs can watch replays, review funnels, dive into retention, and explore their growth metrics. Where other tools stop, Datadog goes even further. It helps you actually diagnose the impact of funnel drop-offs, and bugs, and UX friction. Once you know where to focus, experiments prove what works. I saw this firsthand when I was at Airbnb, where our experimentation platform was critical for analyzing what worked and where things went wrong. And the same team that built the experimentation at Airbnb built Eppo. Datadog then lets you go beyond the numbers with session replay. Watch exactly how users interact with heat maps and scroll maps to truly understand their behavior. And all of this is powered by feature flags that are tied to real-time data, so that you can roll out safely, target precisely, and learn continuously.

(00:51:25):
Datadog is more than engineering metrics. It's where great product teams learn faster, think smarter, and ship with confidence. Request a demo at datadoghq.com/lenny. That's datadoghq.com/lenny.

(00:51:39):
Coming back to this kind of triad, the other element that I hear more and more of is just the skill of taste, and design, and user experience, it feels like that's a very hard skill to learn. And to me, it tells me design is going to be much more valuable in the future.

Marc Andreessen (00:51:54):
Yeah, that's right. And again, here, this is a great example. So again, the task level of, like, "Design the perfect icon," is going to be, all right, the AI's going to do that all day long. If it gives you a thousand icon designs, it's going to be great. It's going to be fantastic, whatever. And by the way, there will still be some level of human icon design or whatever, but AI is going to get really good at that. But what are we trying to do, kind of capital D design of, like, "All right, what is this thing for, and how is this going to function in a world of human beings? And is this going to make people happy when they use it? Is this going to make people feel good about themselves? Is it going to fit into the rest of their life? Is it going to, I don't know, challenge them in the right way?" All of these kinds of higher level questions that the great designers have always thought about.

(00:52:40):
The job of designer will involve much more of those higher level, more important components, and then again, with AI doing a lot more of the underlying tasks. And so one way to think about it is, I don't know, you think of the world's best designers, Jony Ive or whatever, and you could be like, "Wow." Like, if I'm a designer today, if I'm a 25-year-old designer and I aspire to be Jony Ive in a decade, it's all of a sudden, I have a new path that I can use to get there, which is... Because Jony did everything. He did it without AI. Now, a young designer tends to be like, "Wow, if I really harness AI in a decade, I'm going to be like the best designer of the world's ever seen because it's not just going to be me. It's going to be me, plus being so super empowered by this technology to be able to do so much more. And then so much more of my time and attention is going to be able to be focused on these higher-level things that most designers never get to."

(00:53:29):
I think that's going to be another great example of that.

Lenny Rachitsky (00:53:31):
So maybe what I'm hearing here is kind of this T-shaped strategy of if you want to be successful in any three of these roles, be very, very, very good at that specific role: product management, engineering design. And then get good enough at these other two roles.

Marc Andreessen (00:53:45):
I think that's great. I think that's really relevant. And then Scott Adamson, firstly, just passed away, which is a real tragedy. But I referred for years to, actually, Scott Adams. He had this famous career advice he would give people, which I think makes a lot of sense. Which dovetails with what you're saying, which-

Marc Andreessen (00:54:00):
... advice he would give people which I think makes a lot of sense, which dovetails with what you're saying, which is he used to say it's like, look, he said, "I could have been a pretty good cartoonist or I could have been pretty good at business, but the fact that I was a cartoonist who understood business made me spectacularly great at making Dilbert." Because even the world's best cartoonist who didn't understand business could have never written Dilbert, and then the world's best business people who didn't know how to do cartoons couldn't have done Dilbert. It took somebody who actually had both of those skills to be able to make Dilbert which is one of the most successful cartoons in history.

(00:54:32):
And so the way Scott always described it was that from a career development standpoint, the additive effect of being good at two things is more than double. The additive effect of being good at three things is more than triple because you become a super relevant specialist in the combination of the domains, and, look, I mean, you see this all over the economy. I mean, you see this all over the economy, but I'll give you an example. Hollywood, just Hollywood as an example. There are a lot of writers who can't direct a movie and they can be very successful writers. There are a lot of directors who can't write a movie. They can be very successful directors. But the superstars in the entertainment industry are the people who can write and direct. They don't have a term for those. They call us auteurors, and those are the people who are the real creative forces that move the field.

(00:55:20):
And so again, and by the way, Hollywood, actually it's really funny, I've been spending a lot of time talking to Hollywood people about AI. Hollywood has the same Mexican stand-off going right now that we describe in tech, except in Hollywood, for example, for filmmaking, it's the director, it's the writer, and the actor. Because the director is now thinking, "Wow, I don't need the writer anymore because the AI can write the script and I don't need the actor anymore because I can have AI actors." The writer is saying, "Well, I don't need the director because I can direct the movie and the AI can do the actors." And the actor is saying, "I don't need either one of these guys. I can have the AI direct the thing, I can have the AI write the thing and I'm just going to show up and do my performance."

(00:55:53):
And so it's the same kind of triangular configuration, and again, what's great about it is they're all correct. Each person in each of those three fields is going to be able to expand laterally and pick up those additional skills, and then as a consequence, you're going to have more people who can write and direct or write and act or direct and act or do all three.

(00:56:13):
I think to your point, your T-shaped thing, I think that's going to be true basically across the entire economy. And if you think about the T, if you think about the T configuration, it's like, yeah, the breadth, the top of the T is like how many individual domains are you familiar enough with to be able to use the AI tools to be able to do really good work. And then this part of the T is how deep can you go in at least one of those domains so that you really, really deeply know what you're doing. But if you're super deep on coding and you can use AI to do design and you can use AI to do product management, that's your T right there, and you're a triple threat at the top of the T, but with this level of technical grounding underneath that.

(00:56:50):
I mean, at that point, again, you're the super-powered individual, you're going to be able to just perform like sheets of magic, for example, in terms of designing and building your products that people in my generation couldn't have even dreamed of. And so I think that this is a universal kind of theory that I think can apply across the entire economy.

Lenny Rachitsky (00:57:06):
I'm going to invent a new framework right now. Okay, forget the T framework. I'm picturing an F sideways or an E where there's three, two or three, I don't know, downward parts. And so what I'm hearing is get good at least two or three.

Marc Andreessen (00:57:21):
Yeah, I think that's right. I think that's right. Yeah, the combination, yeah. My friend, Larry Summers, had a different version of the Scott Adams thing, which is he used to tell people, he said, " The key for career planning is," he said, "don't be fungible." He's an economist and so that was economic speaking. What that means essentially is don't be replaceable. And so don't be a cog, and what that meant was don't just be one thing. So if you're, quote unquote, again, just a designer, just a product manager, just a coder, then in theory you can be swapped in or out.

(00:57:52):
But if you have this E or F laying on the side kind of thing, and if you have this combination of things that's actually quite rare, then all of a sudden you're not fungible. Not only you're not fungible, you're actually massively important because you're one of the only people in the world who can actually do that combination of things. And yeah, your ability to not become one of those people is just titanically enhanced with AI as compared to anything we've ever seen before.

Lenny Rachitsky (00:58:15):
This is so interesting because I've worked with people that are good at these two skills and they were always called unicorns at the company. She can code and design, oh my god. And what I'm hearing here is this is what you need to become. You need to become really good at at least two things there. I think you used the term smoke stack or something where it's like PM over here, engineer design, and what I'm hearing here is you need to get good at at least two of these skills. The silos of these two roles are disappearing.

Marc Andreessen (00:58:37):
That's right. That's right. And again, I can't overstress the following, for anybody listening to this, the thing about AI that I think people are just not getting enough benefit out of yet is just it will teach you. This is amazing. There's never been a technology before where you could ask it, "Teach me how to do this thing." And so I always feel like it's like people spend too much... it's one of these things where it's like so much focus on figuring out how to use a large language model is like, "Okay, what am I going to try to get it to do for me?" which is of course very important. But the other side of it is, what can I get it to teach me how to do, and it's just as good at that. And so again, this is this level of latent superpower.

(00:59:19):
People who really want to improve themselves and develop their career should be spending every spare hour in my view at this point talking on AI, being like, "All right, train me up. Super empower me. Train me, train me how to be... I'm a coder. Train me how to be a product manager." It will happily do that. It knows exactly how to do that. Run me, make me problems... yeah, make me assignments, then evaluate my results. It will do that just as happily as it will do work, quote unquote, for you.

Lenny Rachitsky (00:59:44):
Two tricks I've heard along those lines. One is to watch the output, what the agent is doing and thinking as it's doing the work. So if you're not an engineer, just sit there and watch it think and make decisions, and it's almost become this layer on top of learning to code is learning to see what the agent is doing and thinking because that teaches you about architecture. And the other is, a couple podcast guests have mentioned this, when you get stuck and then you figure out how to unstuck yourself, you ask it, "What could I have done differently? What could I have said that would've avoided this error in the first place?"

Marc Andreessen (01:00:14):
Yeah, that's right. That's right. Yeah, look, on that first one, and again, this is what I'm doing with my 10-year-old. Yeah, look, if you ask me, yeah, this is a really good point. So if you ask an AI, "Write me this code," and then it does it and it comes back and it doesn't work right, if all you know is single function, I asked it and it gave me back something that's not good, what do you even do with that? You don't understand why it gave you that result. Do you even understand what to tell it to try to get it to do something different?

(01:00:39):
But to your point, if you actually watch what it's doing and then you have the grounding, kind of that leg of your E or your F, if you have that grounding, then you can be like, "Oh, I see what it's doing. I see where it made the mistake. I see where it went sideways." And then you're all of a sudden able to intervene and be able to say, "No, no, that's not what I meant. Do this other thing." And again, this is a big part of having the actual kind of synergistic relationship is that you understand.

(01:01:06):
And by the way, look, I mean, like everything I'm saying is... everything that we're saying right now also is the same as if you're working with human beings. If you and I are colleagues and I would ask you to do something, you'd come back with something completely different, I do need to understand what was happening in your head in order to be able to give you feedback. If I just tell you, "Oh, that's wrong," nothing happens. I need to actually understand. I need to have theory of mind. I need to understand what you were thinking in order to really give you the right feedback. And again, the great thing with AI is AI will happily sit there and explain all day long why it's doing what it's doing. It'll happily critique itself.

(01:01:45):
By the way, this is a very fun thing where you can have one AI critique the other AI which is another thing which is you have one AI write the code, you have another AI debunk the code. And so you can actually, you can play the AIs off against each other and get them to argue with each other. And yeah, these are all the kinds of skills that are going to become, I think, incredibly valuable.

Lenny Rachitsky (01:02:01):
I think people call those LLM councils-

Marc Andreessen (01:02:03):
Yes.

Lenny Rachitsky (01:02:03):
... where they're talking to each other.

Marc Andreessen (01:02:05):
Yeah, that's right. That's right.

Lenny Rachitsky (01:02:07):
I do feel like if I were... I have no design background. I've always wanted to design. I've always wanted to be a great designer. It feels like that's the hardest one to learn of all these three by just watching and talking because there's a lot of exposure hours as folks have used this term, just like how do you learn to be a great designer. That feels like that's going to be really hard and valuable.

Marc Andreessen (01:02:25):
So my true confession is I've always kind of wanted to be a cartoonist, but I have no art skills. But as we're talking, I'm like, "Hmm, it might be time."

Lenny Rachitsky (01:02:35):
The time has come, Marc.

Marc Andreessen (01:02:37):
Yes.

Lenny Rachitsky (01:02:38):
I want to pivot to founders, maybe your bread and butter. You spend a lot of time with the most cutting edge, AI-forward founders. I'm curious what you see them do, how you see them, some way they operate that's maybe blowing your mind about how the future of starting a company looks, how the future of AI-forward companies look.

Marc Andreessen (01:02:57):
Yeah. So this is a great and very topical topic that's all playing out in real time right now on the leading edge. So I think there's like three layers of it and see if this makes sense. I think there's like three layers of it. I think layer one is they're thinking, "All right, how does AI redefine the products themselves?" And this is kind of the time-honored kind of thing that happens with technology transitions, and this is kind of what a lot of venture capital is based on which is, okay, there's a new technology that comes out. Maybe it's the personal computer or the iPhone or the internet or now it's AI, and it's like, all right, is this a new capability that gets added to existing products.

(01:03:35):
So all of a sudden you've got, I don't know, an existing software business and now you've got your PC version of it and now you got your iPhone version of it and you just keep on going and the new technology kind of gets added into the mix with another ingredient to an existing formula, and of course, a lot of new technologies are like that. I don't know when flash storage came out or something, it didn't really redefine the software industry because people just went from using hard disk using flash storage or something. But when the internet came out, like basically old school on-prem software for the most part, not entirely, but a lot of it died and it just got replaced by web software. And so sometimes you get the kind of, it's additive to an existing thing.

(01:04:19):
Sometimes you get the actually it redefines an entire product category, redefines an industry. In many cases, the companies themselves turn over it. So there's sort of this question, and an example you just mentioned, Nano Banana. So a great example is there are these businesses, like just take Adobe. Photoshop is built a, whatever, 40-year franchise in image editing. Okay, is AI a sort of a feature now that gets added to Photoshop to be able to do AI-based image editing, or do you just stop editing images entirely because you're using Nano Banana and all images are just being generated and it's just easier to just have AI generate a new image than it is to try to edit an old one?

(01:04:57):
And so I think there's many areas of tech in which that question is being asked and the answers I think will vary by domain. But obviously as a venture firm, we're betting hard on many of these categories being totally reinvented, and a lot of the best founders are trying to figure out how to do that. So that's kind of AI changing the definition of the product.

(01:05:16):
I think the next layer is actually a lot of what we've already talked about which is AI changing the jobs. And so it's a lot of what we already talked about, but, okay, if I'm a founder of a company and if I have room in my budget for 100 coders, how do I get those coders to be super-empowered AI coders, not the kind of coders I used to have, and if they're super-empowered AI coders, then does that mean, do I still need the 100? Maybe now I only need 10. Or does that mean I still want 100 but now they're doing 10 times more? And so, as you know, a lot of the best founders are working on that right now.

(01:05:48):
And then I think the third shoe to drop hasn't quite dropped yet, but it's kind of the big one which is, all right, the basic idea of having a company, does that change. And again, here you've got this concept of the super-powered individual which is, okay, can you have entire companies where you have basically the founder does everything. Because what the founder's doing is overseeing an army of AI bots. There's kind of this holy grail in our industry that's been running for a long time which is can you have the one-person billion-dollar outcome.

(01:06:21):
We've had a few of those over the years. Bitcoin is probably the most spectacular example with Ethereum right behind it which wasn't quite one person but a very small team. You had Instagram and WhatsApp that had very big outcomes with very small teams. Every once in a while you get one of these things where you just, something hits, and you just have a very small number of people associated with it. But that said, most software companies obviously end up with huge numbers of employees.

(01:06:46):
And so I think the most leading-edge founders are thinking of, okay, how do I reconstitute the actual very definition or idea of having a company and can you have a company that's literally basically just all AI. If you're doing anything in the real world, that's hard, but if you're doing software, that seems like it might be feasible in some cases.

(01:07:08):
And then there's the ultimate example of that which is can you have like autonomous AI economy stuff happening where you have AI bots on the blockchain or something that are basically out there functioning as a business and making money and just literally where the AI does all the work itself and just issues me dividends. Maybe that's the final outlier result. We have a few founders who are chasing that kind of thing. So I would describe that as kind of the latter that the best founders are on.

Lenny Rachitsky (01:07:36):
Super interesting. This whole idea of a one-person billion-dollar company, I think it depends on your definition of what this is, like an outcome I could see. Running my newsletter as one person with some contractors, there's so many little annoying things that I have to deal with, with just support tickets and issues and bugs. It's hard for me to imagine actually a one-person billion-dollar company, even if AI is handling so much of your support because there's just so many random-edge cases that I'm just... like filling out forms. And so I guess depends on, do you have contractors, does that count, what does it mean to be a one person. But I'm just like, "I can't see that happening."

Marc Andreessen (01:08:12):
Yeah. I mean, look, Bitcoin, Satoshi pulled it off.

Lenny Rachitsky (01:08:16):
But the open source community now, does that count? I don't know.

Marc Andreessen (01:08:19):
Yeah.

Lenny Rachitsky (01:08:20):
I guess it counts. Okay.

Marc Andreessen (01:08:21):
Yeah, exactly. Right? So yeah, I would say I don't propose to have answers here, but more just like the smartest people I know or many of the smartest people I know are thinking hard about this.

Lenny Rachitsky (01:08:33):
Yeah. What do you think about moats? A big question constantly in AI, the fact that everything's changing, just what's your guys' thesis on moats in AI? Is that even a thing? Do you care?

Marc Andreessen (01:08:45):
My experience with really big technological transformations, and of course, I kind of lived this directly with the internet and I saw this happen, is the really big technological transformations, they take a long time to play out and there's all of these structural implications that just kind of cascade out over time. There's this rush to judgment upfront where people say, "Oh, it's therefore obvious that X, Y, Z. It's therefore obvious that this kind of company is going to be the company of the future, not that kind. It's obvious that this incumbent's going to be able to adapt and this other one isn't. It's obvious that there's economic opportunity in this kind of startup and not in these others. It's obvious that the moats are going to be in this area of the technology, but not in this other area."

(01:09:25):
What everybody does is they kind of state those things with just an enormous amount of self-assurance where they really sound like they have all the answers. And then what happens is these ideas kind of saturate the media because the media naturally prizes definitive answers over open questions because it... it's like when CNBC is booking guests, they want a guest who's going to come on and say, "Yes, this is the way, it's going to be X." Not like, "You know, I think that's a really good question and let's debate it from eight different angles."

(01:09:51):
What I found is if you look back on those predictions a few years later, and you can do this by the way, if you pull up coverage of the internet from 1993 through 1997, or for that matter even through 2005 or 2010, and you look at the kinds of confidence statements people were making in the first 10 or 15 years, I would say almost all of them were wrong, generally quite badly wrong. And so I think the process, I think there's going to be a massive amount of technological change. It's going to be like, I don't know, five or six layers of structural change that will play out over time.

(01:10:26):
And again, we've talked about a lot of this, but the implications on what are the definition of products, what are the definitions of companies, what are the definitions of jobs, what are the definitions of industries. How does this play out at the national level? How does this play out at the global level? By the way, how does this intersect with politics? How does this intersect with unions? How does this intersect with war? What's China going to do? And so there are just a tremendous number of unknowns, a very, very large number of unknowns, and I think it's just like really, really dangerous to prejudge these things.

(01:11:02):
I'll just run this as a thought experiment and you can see what you think on this, but it's like, are AI models themselves defensible. Is there a moat on AI models? And on the one hand, you'd be like, "Wow, it certainly seems like there is or should be," because if something takes billions of dollars to build and you need this incredible critical mass of computing data and there's only a certain number of engineers in the world that know how to do this and they are getting paid like MBA stars. And then these companies have to deal with all these crazy political issues and press issues and reputational stuff and regulatory and legal.

(01:11:40):
All of that translates to, okay, probably at the end of this, there's going to be two or three companies that are going to end up with like 100%, I don't know, whatever, 50/50 or 30/30/30 or 90/10 and one, or whatever it is, market share and then they're going to have whatever profitability they have and it's going to be kind of a classic oligopoly, or maybe one company's going to win definitively and it'll be a monopoly. And by the way, those outcomes have happened in software many times before. And so maybe that will be the outcome.

(01:12:05):
The other side of it is if you had told me three years ago that in the Christmas of ChatGPT that within basically a year to year and a half there would be five other American companies that would have basically exactly capable products, and then there would be another five companies out of China that would have exactly capable products, and then there would additionally be open source that was basically the same, I would have been like, "Wow, the thing that seemed like it was black magic all of a sudden has become like commoditized really fast," which by the way, is exactly what happened. Within a year of GPT3 coming out, there were there open source GPT3s running on a fraction of the hardware that were available for free. And then there were five. Now you've got, fully in the game, you've got Google and you've got Anthropic and you've got xAI and you've got Meta and you've got all these other companies that are... and then DeepSeek and Kimi and all these other Chinese companies. And so even at the level of LLMs or AI models, you can squint and make that argument either way.

(01:13:05):
By the way, same thing at the level of apps. It's like one school of thought is apps are not a thing because the model's just going to do everything, but another way of looking at it is no, actually adapting the model is kind of the engine into a domain involving human beings where you need to actually have it fit for purpose to be able to function in the medical industry or the legal industry or whatever or coding. No, you actually need the application level's actually going to matter enormously, and maybe the LLMs commoditize and maybe the value goes to the apps. And again, you can kind of squint either way on that one, and I know very smart people who are on both sides of that argument.

(01:13:41):
And so my honest answer on this is I think we're in a process of discovery over time. The way I think about this kind of structurally is it's a complex adaptive system. The technology itself provides one of the inputs. The legal and regulatory process is another input. Actual individual choices made by entrepreneurs matter a lot. The economics matter a lot. Availability of investor capital varies over time, that matters a lot. This is a complex system, and so we actually don't know the outcomes on this yet. We need to be open to surprises at the structural level of what happens.

(01:14:19):
And of course, as a VC, this is very exciting because it means we're doing this now. We should make bets along every one of these strategies and see how this plays out. I would just say, there may be, I don't know, there may be like one particularly brilliant, I don't know, hedge fund manager or something who has this all figured out, but I guess I would say if they exist I haven't met them yet.

Lenny Rachitsky (01:14:40):
So what I'm hearing here is don't over-obsess with moats at this point because we have no idea what'll end up being, and as much as it may feel like, okay, there's no way OpenAI will lose this lead, clearly we're seeing a lot of competition. GPT wrapper point is really great. It was such a derogatory term, I don't know, a year ago, just like, "You're just a GPT wrapper." Now it's like the companies that are the biggest companies, the fastest growing companies in the world.

Marc Andreessen (01:15:01):
Yeah. Well, it's like a little bit like, I don't know, I mean, even just like with... this has been the holiday, three years ago was the holiday of ChatGPT. This last month or whatever has been the holiday of Claude, particularly Claude Code for coding. But it's pretty amazing because it's like, okay, there was Claude which is obviously a great accomplishment, but then there's Claude Code which is an app. It's a Claude wrapper. It's agent harness. And then they did this amazing thing where they came out with, was it Coworker?

Lenny Rachitsky (01:15:01):
Cowork.

Marc Andreessen (01:15:29):
Cowork. And remember what they said of Cowork, which is Claude Code worked Cowork in a week.

Lenny Rachitsky (01:15:36):
Yeah, a week and a half, yep, 100%.

Marc Andreessen (01:15:39):
Well, and there's two ways looking at that which is like, "Wow, that's really..." I mean, obviously that's really impressive that Claude Code was able to build Cowork in a week and a half. That's great. That's amazing. The other way to look at it is Cowork was developed in a week and a half. How much complexity could there be? How much of a barrier to entry can there be in something that was developed in a week and a half? And then again, it's this push and this pull thing where it's like, wow, it's incredibly functional, incredibly valuable, and people all over the world and every day now are like, "Wow, I can't believe what I can do with this. It's like the most magical product ever." But at the same time, it took a week and a half.

(01:16:16):
And so every other model company, I'm sure, you'd have to expect, is sitting there being like, "Okay, obviously we need to build an Asian artist and then obviously we need to build a Cowork thing for regular people." I'm not even saying I know anything, but just obviously they're all going to do that. And so how defensible is that? In six months, and we've seen this happen before, is Claude Code going to get lapped the same way that GitHub Copilot got lapped? The history in the last three years has been everything that looks like it's like the fundamental breakthrough gets basically replicated and lapped very quickly. Many of the smartest people I know in the field, when I really talk to them, kind of get a couple drinks into them, they're like, "Yeah."

(01:16:55):
One theory is there really aren't any secrets among the big labs. The big labs kind of all have the same information and they kind of have all the same knowledge and they lap each other on a regular basis, but there's not a lot of proprietary anything at this point. And then again, evidence of that is DeepSeek came out of left field and basically was like a re-implementation of a lot of the ideas under American big labs and had some original ideas of its own. But, wow, it wasn't that hard for some basically a hedge fund in China to do it, and so how much defensibility is there.

(01:17:26):
But on the other side of it, you've got, wow, these big labs are now paying individual engineers like they're rock stars and they're incredibly bright and creative people. Maybe there's a dozen nascent ideas at any one of these labs that is actually going to be a huge breakthrough that's going to be hard to replicate. And so again, it's just like, I think we just need... I don't know, my view is I need to put a big discount on my forecasting ability on this one.

(01:17:49):
For me, it's much less interesting to try to say, "Okay, as a consequence, industry structure in five years is going to be X, the big winner and the category is going to be company Y, the big product killer app is going to be Z." It's like, I don't think I can predict that. I think a much better use of my time is being very flexible and adaptable at a time like this.

Lenny Rachitsky (01:18:07):
So with all this in mind, do you feel like there's something you're paying attention to more to help you decide, okay, this is where we want to place our bet, or is the answer essentially the strategy you guys have, which is place a lot of bets? You guys raised the largest fund in history. Is that the way you win in this world?

Marc Andreessen (01:18:23):
Yeah. I mean, for us, yeah. For us, we obviously have a very deliberate strategy. One way to think about this the Peter Thiel... You remember the Peter Thiel formulation of... he said, "There's a two by two, there's optimism and pessimism, and then there's determinant and, is it indeterminate, and indeterminate." And so he always argued that Silicon Valley is characterized by too much what he calls indeterminate optimism. What he meant by that is basically, I think the way he would describe it is an indeterminate optimist who thinks the world is going to be better but can't explain why. Some combination of things is going to happen to make the world be better even if we don't know what those things are. I think he at least historically would say that's basically... that risks at least being just wishful thinking or delusional thinking.

(01:19:11):
What the world needs more is determinant optimists, which are people who are like, "No, the world is going to be better because I'm going to do this specific thing." He would classify, for example, Elon, he would sort of maybe say VCs are indeterminate optimists and then he would say Elon is the determinant optimist where it's like, no, I'm going to build the electric car, I'm going to do solar, and then I'm going to do Mars and these very concrete things.

(01:19:35):
I think there's a lot to Peter's framework, but the way I would describe it is I think maybe if he and I disagree with part of that it would be I think the indeterminate optimism is a stronger phenomenon than at least I think he's historically represented it as, and I would put myself firmly in the indeterminate optimist category, and that's the strategy that we have at a16z which is... and the reason for that is hopefully it's not so much wishful thinking. It's more, no, the indeterminate optimism of venture capital or the indeterminate optimism of a16z or Silicon Valley is actually very specific which is there are these extremely bright and capable people, like Elon and many others, who are founders and kind of product creators. Each of those individual people is a determinant optimist. Each of them individually has a very strong view of what they're going to do, but the great virtue of the capitalist system, the great virtue of the American economy, the great virtue of Silicon Valley is we don't just have one of those and we don't just have 10 of those. We have 100 and a thousand and then 10,000 of those.

(01:20:34):
The way to optimize the outcome is to have as many of those as possible be as good as possible, run as hard as possible. And then just the nature of the future is like we just don't know all the answers and that's okay. And then the right way to deal with that is to run as many experiments as possible and have as many smart people try to do as many interesting things as possible. And so, yeah, I would put myself firmly on the side of the indeterminate optimistic.

Lenny Rachitsky (01:20:55):
I'm wondering if the answer to the question of what you look for now more and more is this determinant optimistic founder that has this massive ambition and is-

Lenny Rachitsky (01:21:00):
... [inaudible 01:21:00] Optimistic founder-

Marc Andreessen (01:21:01):
Yeah.

Lenny Rachitsky (01:21:02):
... and has this massive ambition and is actually working on achieving it.

Marc Andreessen (01:21:06):
Yeah, yeah. No, that's right, that's right. I mean look, the founders need to be determinate optimists. They need to have a very specific plan. And look, the critique always... The critique from the founders is, "Oh UVCs have it easy, because you don't actually have to commit, right? You don't actually have to, like, make... You have to make the bed you lay in, you can, like, place multiple bets you can have. Whereas a portfolio, you should have a lot more sympathy for us as founders, because we only get to make the one bet."

(01:21:31):
And there's truth to that. The kind of argument on that is the founders get to run their companies, we don't. So, we don't get to put our hand on the steering wheel. And so, the great virtue of being a determinant optimist is you actually get to single-mindedly execute against that goal.

(01:21:48):
And look, in the long run, who does history remember? History remembers Henry Ford, right, not whoever was, whatever the seed investor who seeded Ford Motor Company, and 10 other car companies have failed. Right?

(01:21:58):
And so, the determinant optimist is the founder of the company builder and the engineer, and these are the people who actually use the sign, and deserve 99.9999% of the credit. But you know, having said that, I do think there is a role for having some indeterminate optimists in the background, no, helping along the way, and helping keep the whole cycle going.

Lenny Rachitsky (01:22:18):
Do you think about AGI in shifting your investment thesis? Like, as we approach AGI and hit AGI, as an investor, how do you think about your investment thesis changing?

Marc Andreessen (01:22:29):
Yeah, so I've always kind of had a little bit of an issue... I've always kind of struggled with the concept of AGI because at least... Well, let's put it this way. Let's define terms which is where I kind of struggle with it. Which is, there's like the prosaic definition of AGI, and then there's like the cosmic definition.

(01:22:48):
And the way I describe it as, so let me start with the cosmic one. So the cosmic one is basically, is the singularity, right? And so, AGI is the moment where you enter the singularity which is to say where the world fundamentally changes. And the rules of the old world are gone, we're now operating in a new domain.

(01:23:04):
And then the full definition of singularity is it's a world in which human judgment is no longer really relevant because you get this self-improvement loop, the AI is improving itself. In a sort of race circle takeoff scenarios, you could see if this takeoff thing, where the AI's improving itself, and the machines are making decisions so much faster than people, and people are just sitting there watching the machine do its thing.

(01:23:26):
And I kind of described it, I don't really think we live in that world, whether they could call that utopian or dystopian, I don't think we're lucky or unlucky enough to live in that world. We could debate that, we could talk about that more.

(01:23:37):
But the prosaic definition of AGI that at least I think the industry purchases but it's kind of conversed on, and tell me if you agree with this, is when the AI could do every economically-relevant task as good as a person.

Lenny Rachitsky (01:23:47):
The way the co-founder of Anthropic put it is, like, "A basket of the most valuable economic tasks," so it's, like, 10, 15, not every single economically-valuable task.

Marc Andreessen (01:23:56):
Okay, got it. Yeah, so it's maybe even a slightly reduced definition. And by the way, we're clearly getting close to that if we're not already there.

(01:24:04):
And so on that one, I kind of feel like, so I kind of feel like the cosmic one overstates what's going to happen. And then I kind of feel like the kind of AGI definition that you just gave, I think it kind of understates what's going to happen. It's almost too reductionist.

(01:24:17):
And the reason for that is, I don't think there's any reason to assume that human skill level is the cap on anything. Right? And so the way we say that is AGI always is the definition you gave, the definition I gave. It's always kind of relative in comparison to a human worker, right?

(01:24:33):
And it's, like, I don't know, human skill level caps out at a certain point, but that's because of the inherent biological limitations of the human organism. Right? Human, I gave you an example. Human IQ, kind of what they call "fluid intelligence," or the sort of G factor of fluid intelligence, IQ I think tops out in humans as a species, it tops out around 160.

(01:24:56):
Right? Where at like 160 it's like Einstein level, Einstein [inaudible 01:25:00]-

Lenny Rachitsky (01:24:59):
In terms of IQ. Yeah.

Marc Andreessen (01:25:02):
... in terms of IQ. Like, it just tops out at 160. The 160 IQ people are the ones who come up with new physics, there's only a small handful of those. Generally speaking, when we run into somebody in the world who's like incredibly smart, who's like a bestselling author, or like a, you know, one of the world's best, I don't know, research scientists, or one of the world's best doctors, whatever it would be, probably 140 is kind of the IQ that you're looking for there.

(01:25:26):
If you're looking for a really good lawyer, it's probably 130. If you're looking for a really good line manager in a business, it's probably 110. If you're looking for an accountant, like a small business accountant, who's good at doing the books for small businesses, it's probably 105. Right?

(01:25:41):
And so the kind of scope of impressive human... The ability of the human organism to do intellectually impressive things, it's sort of that 110 to 160 is kind of the spectrum, and good news is there's a lot of those people running around, but there's not that many at 140, 150, 160.

(01:25:57):
But it's like, that's like the limitations of what can fit in here, right? And it's like, there's no theoretical limit on where this goes if you release the limitations of human biology, right? And so, can you have a... And you already have people running these experiments to kind of do human-equivalent kind of IQ for existing AI models.

(01:26:17):
And by the way, existing AI models are kind of testing around the 130, 140 level, which means they're going to get to the 160 level. And they're arguably on the math side starting to get to the 160 level now.

(01:26:26):
But I think we're going to have AI models relatively quickly that are going to be like 160, 180, 200, 250, 300. By the way, and I think that's great, right? I feel as great about that as I do about the fact that we occasionally get an Einstein. Right?

(01:26:41):
It's like, would the world be better off or worse off with more or fewer Einsteins? And the answer is, of course the world would be better off with more Einsteins, and of course the world would be better off with machines that have more IQ like Einstein or greater than Einstein.

(01:26:51):
But I think IQ of the machines is going to exceed that of the humans, I think that's really good. And then the performance, again, it goes back to like the AI coding thing that's happening. Performance against task is going to get better also.

(01:27:02):
I think this is where Linus Torvalds in particular was like, "Yeah, okay, this thing is starting to generate better code than I can." Okay? So now we're going to have AI coders that are actually better coders than the best human coders. I think that's... Right?

(01:27:13):
I think we're going to have AI doctors that are better than the best human doctors, I think we're going to have AI lawyers that are better than the best human lawyers, which actually is going to be very interesting to see, which we can talk about. Which I think is also great.

(01:27:24):
And so, I don't think there's a... I think we're used to living in a world where we just don't understand how good good can get, because we've been capped by our own biology. And we're going to get to experience what it's like when you have the capability at your fingertips, that's actually better than human in these domains.

(01:27:38):
So you see what I'm saying, which is, like, I think this idea of human equivalent is just going to be a footnote. It's like, "Oh yeah, that was just on Tuesday, in 2026 is when they hit that." And it kind of didn't matter because the next question was, like, "Okay, what do we get to do in a world where we actually have machines that are better than that?" Right?

(01:27:58):
And so, I think this is going to be much more of an exploratory process for actually seeding human capability than it's going to be any sort of particular singular singularity moment or whatever that happens, that just happens to coincide with the human threshold.

Lenny Rachitsky (01:28:10):
200 IQ, I... Just like that frame of reference is such a mind-expanding way to think about just how fast and how smart these things are going to get, and quickly.

Marc Andreessen (01:28:20):
Well, I don't know if you have this experience, I have this experience all the time. Well, two experiences I have all the time. One is just like, I know I ought to be able to do this, but I just can't... It's going to take too long, I want to write this thing, or I want to... Whatever, I want to have this theory on this thing, or to have a plan or whatever.

(01:28:39):
And it's just like, "Fuck," I don't have the eight hours, or by the way, the eight weeks or the eight years, right? And I just don't know enough yet, and I'm just, like, I can't do the math in my head, and my memory isn't perfect, and I can't remember, and I read... I don't know if you have this, you get interested in something, you read 10 books. And then you're like, "Shit, I forgot almost everything I just read."

(01:29:01):
I wish I could retain it all but I can't. It's just like you just have this... I sort of live in this state of endless frustration. And so it's like, if I could just be smarter than I was, I'd be much better at what I do, but I'm not. So there's that.

(01:29:14):
And I don't know how often you have this, but I have this on a regular basis. It's just like, "I," because of what we do, I know a bunch of people who I know for fucking sure are smarter than I am. And I know it because when I talk to them, I just find myself at a certain point. It's like for the first half of the conversation, I'm just taking notes the entire time. And for the second half of the conversation, I'm just like, "Fuck," like, "Fuck me." Like, this person is just smarter than I am, and they're just out-thinking me, and they're going to keep out-thinking me, and I just can't, and I'm just like, "All right, goddammit. I've got to go home and I've got to have a drink."

(01:29:43):
Because I'm just not... Whatever that is, I'm not that. And so, we're just so used to having those limitations, that the idea of having machines that work for us that don't have those limitations, I just... I think that's much more exciting than people are giving it credit for.

Lenny Rachitsky (01:30:00):
Oh man. I could talk to you for hours, Mark. I'm thinking to close out the conversation, I want to ask about your media diet and your product diet. You just talked about books, 10 books, I think you famously read constantly. I saw an interview with you where you're just like, "Airpods changed my life, I'm just listening to audiobooks now all the time."

(01:30:17):
So in terms of a media diet, what are you reading, what are you paying attention to these days in terms, I don't know, podcasts, newsletters, blogs, things like that, and then any books in particular?

Marc Andreessen (01:30:25):
Yeah, yeah. So what I read is basically, I mean I read... So I read basically three categories of things. So in terms of general media, it's basically I sort of... I always describe it as I have an almost perfect barbell strategy, which is I read X, and I read old books. Right?

(01:30:41):
So it's basically either, like, up-to-the minute what's happening right now, or it's like a book that was written 50 years ago that has stood the test of time, and then where presumably there's something timeless in it. And then it's sort of everything in the middle, I'm always much more skeptical about.

(01:30:56):
And in particular, it's kind of what I already said, which is I think if you go back and you read old... Nobody ever does this, it's actually really funny, there's no market for it. But if you go back and you read old newspapers... And by the way, you can do this, just read the last week's newspaper, right? Yeah, today, so we're taping on Friday. So read last Friday's newspaper, right?

(01:31:15):
And just go back and read it, and be like, "Oh my God. None of this happened. None of what they predicted played out the way that they said that it would. None of this turned out to actually be that relevant or correct." They didn't understand, by the way, they had no view of what was going to happen this week. Then they couldn't know, and so they were making predictions and forecasts and so forth based on not having information.

(01:31:37):
But it's like, "Wow, none of this happened, I wish I had never read this, oh my God." And then it's kind of the same thing with magazines, I go back and read old magazines, and just the level of just the endless numbers of predictions that they make. And kind of, you know, the problem with... Newspapers at least they're going day-to-day, the thing with magazines is it's like a week or month kind of a long cycle.

(01:31:58):
And so by the time an article even hits publication, it's often out of date. So I just have a big problem with kind of everything in the middle. And so it's either of the moment or timeless. But then yeah, you mentioned newsletters. I mean, so the other thing, and this is maybe obvious, but I think it's probably still underrated, which is actual practitioners in the field who are actually creating content, I think probably is still dramatically underrated.

(01:32:21):
And I think this is a huge part of the Substack phenomenon, and the newsletter phenomenon, and the podcast phenomenon, is, like, direct exposure to the people who are actually principals in the field who actually know what they're talking about is probably still dramatically underrated.

(01:32:33):
And I think again, the reason for that is like we're used to being in this mass media kind of culture in which basically everything is mediated. Right? Everything got filtered through like TV interviews or, like, newspaper interviews, or magazine interviews. And obviously now more and more it's just, no, you actually want smart people who are actually working on something explaining themselves.

(01:32:49):
And then you have tons of intermediation, like podcasts, that kind of open that up for people and make that possible. And so yeah, domain practitioners are really great. I mean, yeah, just to state the obvious in AI, it's obviously your stuff, but also, like, the fact that Lex Fridman can have the world's leading... And any of you guys, there's a small handful of you guys who have access to these people, you could have the world's leading experts in the domain actually show up.

(01:33:15):
And by the way, and look, the critique always is, people talk their book, like if I'm running a startup or whatever I'm just selling. But it's like... And there's always a little bit of that... But it's also, my experience is people love to talk about what they do. And they fundamentally want to express what they do, and they want to explain it, and they want people to understand it.

(01:33:35):
And everybody kind of enjoys that, and they get to contribute to human knowledge by doing that, and they get ego gratification by doing that. And so I think there's actually just tremendous amounts of alpha in listening to the world's leading experts in the space who actually just show up and talk about what they're doing.

(01:33:48):
And of course the world is awash in that today in a way that it wasn't as recently as 10 years ago. So yeah, I do as much of that as I can too.

Lenny Rachitsky (01:33:54):
And there's also just this culture in tech, Silicon Valley, in particular, of sharing, or not trying to keep these secrets. Everyone on LinkedIn is always like, "How is this free?" Like, it's just the way it works.

Marc Andreessen (01:34:04):
Yeah. Somebody said, "Silicon Valley is a company town, but they company is Silicon Valley." Right? And again, at the loneliest coast, again, is one of these great n equals one. If the level of n equals one is somebody, and I've run startups before, I've run companies before, if the level of n equals one of, like, running a company, that's just a giant pain in the fucking butt.

(01:34:22):
Because your secrets are walking out the door, and your employees are walking out the door, and the whole thing sucks. But the other side of it is you also benefit from that, right? Because you get to hire people with all these skills and experiences, right, and you're in this ecosystem that adapts and channels talents and skill and knowledge and people into the new fields.

(01:34:38):
So there's kind of the push and pull of that at the level of just being an individual CEO. At the level of just being in the ecosystem to your point, yeah, it's an absolutely magical phenomenon. And by the way, for all of the issues in Silicon Valley, I did the count once, I think AI is the ninth major technology platform in the history of Silicon Valley. Right?

(01:35:03):
Silicon Valley is still called Silicon Valley, we haven't made Silicon here in decades. Right? We used to actually... You know it's called Silicon Valley because they used to make chips, right? They used to have the actual fabs were in Silicon Valley. And then they designed them and they made the chips.

(01:35:15):
And so, and that was wave one starting in the 19... No, that was actually, no, that was more wave three or whatever. But that was when the area was named in the 1950s. But now we're on wave nine. Right?

(01:35:28):
And the company town phenomenon where the company is, the industry, again, the indeterminate optimism, nobody had to sit and plan and say, "Okay, in the 1990s Silicon Valley's going to do the internet, in the 2000s they're going to do the smartphone, in the 2010s they're going to do the cloud, in the 2020s they're going to do AI."

(01:35:44):
It's just, right, the indeterminate optimism of ecosystem flexibility of the ecosystem that they Silicon Valley could morph into all these categories, and again, maybe a testimony to indeterminate optimism.

Lenny Rachitsky (01:35:58):
This reminds me of the meme of how we're all just wrappers over sand, everything we're building is just wrapper over wrapper, wrapper, wrapper.

Marc Andreessen (01:36:03):
The wrapper thing is hysterical, yeah, yeah. I'm a software company and I'm a chip wrapper, right?

Lenny Rachitsky (01:36:07):
Yeah.

Marc Andreessen (01:36:08):
Yeah. I'm a business application, I'm a database wrapper. Yeah, exactly. I'm a sand... I mean, you and I, we're all now sand wrappers.

Lenny Rachitsky (01:36:15):
Sand wrappers.

Marc Andreessen (01:36:17):
Perfect.

Lenny Rachitsky (01:36:17):
Okay. One more question along the media diet, I asked your partner Ben Horowitz what to talk to you about. This is a16z if people don't know him. And he said you're really into movies these days.

Marc Andreessen (01:36:27):
Yeah.

Lenny Rachitsky (01:36:28):
And so I don't know, any movies? Any movies you're really into these days, any movies you've absolutely loved recently?

Marc Andreessen (01:36:33):
Yeah, so the movies that blew my socks off last year, which I think is the best movie of the decade for sure and maybe of the last, like, 15 years, is this movie. Unfortunately it's one of these things, not a lot of people have seen it, but I would encourage it. It's called Eddington.

Lenny Rachitsky (01:36:48):
I've not heard of it.

Marc Andreessen (01:36:48):
Have you not heard of it? Okay, so you're going to really enjoy it. So, I won't spoil too much of it, so at the surface level the following spoils nothing. So at the surface level, it's set in a small town in New Mexico called Eddington which is a small town about 600 people.

(01:37:04):
And there's a sheriff who's played by Joaquin Phoenix who's like an old, crusty, basically right-winger, and then there's a mayor played by Pedro Pascal who's basically a young, hip, progressive. And then the movie starts I think in March of 2020.

(01:37:21):
And so it starts when COVID first hits. And then it sort of as it plays out over the next few months, it intersects, and it sort of extends into the summer of 2020. So, kind of the George Floyd moment and then protests and riots and kind of everything.

(01:37:36):
So sort of the convergence of COVID and then all the BLM stuff. And then there's a third kind of element to it which is there's a company which is basically a loosely-disguised version of Meta if you read the backstory of it, which is building an AI data center on the outskirts of town. So they kind of pull that in as sort of a thing that looms larger and larger over time.

(01:37:58):
And then the thing it really is great at is it really shows, you know, this is a small town in New Mexico. And so, everybody in the town gets full wrapped up in all the COVID stuff, and they get fully wrapped up in all the BLM stuff, and they get fully wrapped up in all the tech anxiety stuff.

(01:38:13):
But they're all experiencing it basically through the internet, right? Which is what actually happened, right? So the reason I love the movie so much is one is it's the first movie that directly grapples with 2020, of what happened in 2020, and it just, like, fully, fully engages and grapples with all the dynamics that were playing out in the country.

(01:38:31):
But the other reason is it's the first movie that does a really good job of showing what it was like especially in that area to live in a world in which there were things happening in the real world, and people were kind of experiencing events online, like in a way that was very central in their lives. Right?

(01:38:45):
And so it does a really good job of pulling in smartphones and social media in a way that movies really, really, really struggle with, and then the whole thing comes together in an incredibly entertaining way.

(01:38:55):
And so I wouldn't even say I completely agree with the movie or whatever, and I think the director of the movie and I would probably disagree about a lot, but he really tries hard to really grapple with what it's actually like to live like a human being in the 2020s in America in a way that I think many other filmmakers who are very talented have just been very scared of touching.

(01:39:14):
And this guy, for some reason he's just like, "Yeah, I'm just going find all the third rails and I'm just going to fucking grab them."

Lenny Rachitsky (01:39:19):
I can see why that's your favorite movie of the year.

Marc Andreessen (01:39:22):
It's great, it's great, it's great. Everybody should see it.

Lenny Rachitsky (01:39:24):
Oh man. Okay, final question, I want to ask about your product diet. Are there any products you use that maybe are less known that you love, that you want to recommend? You can mention products you're investors in if you use them constantly.

Marc Andreessen (01:39:38):
We have so many that it's really hard to, you know, I always feel it's who's your favorite shoulder? And so it's really hard to pull out specific ones. But I'll talk about a few. I mean they're all just observations. So one is my 10-year-old, I have, my 10-year-old is 100% obsessed with Replit. And by the way, it was not from me. Do you have kids?

Lenny Rachitsky (01:40:00):
I do, I have one two-and-a-half year old.

Marc Andreessen (01:40:02):
Two-and-a-half. Okay, so you haven't run into what I'm running into now, which is whatever it is that you do is not cool. Right? Like, it's two-and-a-half, whatever daddy does is like the coolest thing in the fucking world. I can tell you, by the time he's 10, whatever you do is, like, deeply uncool.

(01:40:15):
Right? And I'm highly aware of that. And so, like, if I mention, "Oh yeah, we work on XYZ," he's like, "Okay." But when he discovers something, then it's cool, or when his friends tell him about it it's cool. And so he through no interference on my part discovered Replit about three months ago, and discovered Vibe coding, and is completely obsessed with Vibe coding games, and all kinds of things and literally will sit and do it for hours.

(01:40:39):
And so I'm seeing that phenomenon play out, which is super fun. That's one. Two is, I am just completely in love with all the AI stuff. I think it's just absolutely amazing, hysterical. My favorite party trick at dinner parties now is to pull out Grok with Bad Rudy, which is, if you've seen, it's a foul-mouthed raccoon avatar in the OS Grok app.

(01:41:04):
So, I think that's super fun. We have this company, Sesame, that they went viral last year for these just incredibly, like, intimate emotional kind of voice experiences. So I think the voice stuff is fantastic.

(01:41:18):
But I'm also a super fascinated by all the voice input stuff. And so Limitless Suite, yeah, Limitless recently, the company recently sold, but all the... I think the pendants, the wearables, all that stuff is going to be big, the Meta glasses. I think there's going to be a whole wearables revolution here.

(01:41:36):
I love the voice input stuff. There's this app on my phone now called Whisper Flow, which is voice transcription, which works like staggeringly well. It's incredible, it's like a voice transcription function, but you can actually talk to the AI model while you're doing voice transcription. So it kind of understands when you're telling it, "No, no, I want bullet points over there and I want this and that."

(01:41:58):
And it understands that you're not telling it to type in the words "I want bullet points," it just actually understands that you want bullet points. And so that's a great example of a super useful thing. And so, I think the voice mode stuff is going to be really great.

Lenny Rachitsky (01:42:10):
Subscribers of my newsletter get a year free of Replit and Whisper Flow, so there we go. What's the most memorable thing your son's built with Replit?

Marc Andreessen (01:42:19):
Oh, well so, he's gotten super into Star Trek. And so, so far he's writing, like, Star Trek simulators. So like all the, you know, all the... By The Next Generation, they actually have a-

Lenny Rachitsky (01:42:29):
Next Generation, okay, I was going to ask which-

Marc Andreessen (01:42:30):
Well actually, we like them all. We watched the new Star Fleet Academy last night-

Lenny Rachitsky (01:42:33):
Hm.

Marc Andreessen (01:42:33):
... which actually is quite good. But we watched the original, we watched them all. But it was in Next Generation where they actually developed an actual design language for the computers. If you watch the original series, they just had, like, basically knobs with lights.

(01:42:46):
And they didn't really, they just were, like, fucking around on set, and trying to pretend they were doing it. But by Next Generation, they actually had designed, they actually had a UI design language. And so one of the fun things you can do with Vibe coding is you can say, "Give me a Star Trek Next Generation user interface for whatever, this, that," or whatever.

(01:43:02):
And it actually uses the, they called it... I'm just having a nerd-out... They called it LCARS design language. And it'll actually build you like Star Trek Next Generation bridge consoles using that design language, but with your choice of a Star Trek name, for example.

(01:43:17):
And so he's going crazy for that kind of thing.

Lenny Rachitsky (01:43:19):
That sounds extremely delightful. You guys should open source and release that. Marc, like I said, I could talk to you for hours, well, you've got things to do. Anything you want to leave listeners with before we wrap up? Anything you want to double-down on or just leave listeners with?

Marc Andreessen (01:43:33):
Yeah, so a couple things. So one is, we got super lucky last week, Packy McCormick wrote the best piece ever written about us, actually, which he released. And so it's the best explanation of what we do, and how we think. And so I would definitely recommend that.

(01:43:46):
And then we're putting a lot, we have a great team of folks now, we're putting a lot of effort ourselves into video and content. And so I'd definitely recommend our YouTube channel, which I think has a lot of great stuff and is going to be very exciting in the next year.

Lenny Rachitsky (01:43:59):
Awesome. Well link to that, I think it's just youtube.com/a16z, something like that. And you guys have great stuff.

Marc Andreessen (01:44:04):
Okay.

Lenny Rachitsky (01:44:04):
Marc, thank you so much for being here.

Marc Andreessen (01:44:06):
Awesome, thank you for having me. I really appreciate it.

Lenny Rachitsky (01:44:08):
Bye everyone.

(01:44:10):
Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review, as that really helps other listeners find the podcast.

(01:44:25):
You can find all past episodes or learn more about the show at lennyspodcast.com. See you in the next episode.

